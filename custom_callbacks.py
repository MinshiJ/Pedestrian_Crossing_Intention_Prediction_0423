#!/usr/bin/env python3
"""
Custom callbacks for training models
"""

import os
import json
import yaml
import pickle
import numpy as np
import tensorflow as tf
from datetime import datetime


class EpochSaveCallback(tf.keras.callbacks.Callback):
    """
    è‡ªå®šä¹‰å›è°ƒå‡½æ•°ï¼šä¿å­˜æ¯ä¸ªepochçš„æ¨¡å‹å’Œè®­ç»ƒä¿¡æ¯
    """
    
    def __init__(self, save_dir, save_best_k=5, monitor='val_loss', mode='min', 
                 save_weights_only=False, save_format='h5'):
        """
        Args:
            save_dir: ä¿å­˜ç›®å½•
            save_best_k: ä¿å­˜æœ€å¥½çš„kä¸ªæ¨¡å‹
            monitor: ç›‘æ§çš„æŒ‡æ ‡
            mode: 'min' æˆ– 'max'
            save_weights_only: æ˜¯å¦åªä¿å­˜æƒé‡
            save_format: ä¿å­˜æ ¼å¼ 'h5' æˆ– 'tf'
        """
        super().__init__()
        self.save_dir = save_dir
        self.save_best_k = save_best_k
        self.monitor = monitor
        self.mode = mode
        self.save_weights_only = save_weights_only
        self.save_format = save_format
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        os.makedirs(os.path.join(save_dir, 'epochs'), exist_ok=True)
        os.makedirs(os.path.join(save_dir, 'best_models'), exist_ok=True)
        
        # è·Ÿè¸ªæœ€ä½³æ¨¡å‹
        self.best_models = []  # [(score, epoch, filepath), ...]
        
        # è®­ç»ƒå†å²è®°å½•
        self.epoch_history = []
        
    def on_epoch_end(self, epoch, logs=None):
        """æ¯ä¸ªepochç»“æŸæ—¶è°ƒç”¨"""
        logs = logs or {}
        current_score = logs.get(self.monitor)
        
        if current_score is None:
            print(f"Warning: {self.monitor} not found in logs")
            return
        
        # ä¿å­˜å½“å‰epochä¿¡æ¯
        epoch_info = {
            'epoch': epoch + 1,
            'timestamp': datetime.now().isoformat(),
            **logs
        }
        self.epoch_history.append(epoch_info)
        
        # 1. ä¿å­˜æ¯ä¸ªepochçš„æ¨¡å‹
        epoch_filename = f"epoch_{epoch+1:03d}_loss_{logs.get('val_loss', 0):.4f}_acc_{logs.get('val_accuracy', 0):.4f}"
        if self.save_format == 'h5':
            epoch_filepath = os.path.join(self.save_dir, 'epochs', f"{epoch_filename}.h5")
            if self.save_weights_only:
                self.model.save_weights(epoch_filepath)
            else:
                self.model.save(epoch_filepath)
        else:
            epoch_filepath = os.path.join(self.save_dir, 'epochs', epoch_filename)
            self.model.save(epoch_filepath, save_format='tf')
        
        # print(f"ğŸ’¾ Saved epoch model: {os.path.basename(epoch_filepath)}")
        
        # 2. ç®¡ç†æœ€ä½³æ¨¡å‹
        self._manage_best_models(current_score, epoch + 1, epoch_filepath)
        
        # 3. ä¿å­˜è®­ç»ƒå†å²
        self._save_training_history()
        
        # 4. æ‰“å°epochæ‘˜è¦
        self._print_epoch_summary(epoch + 1, logs)
    
    def _manage_best_models(self, current_score, epoch, epoch_filepath):
        """ç®¡ç†æœ€ä½³æ¨¡å‹ä¿å­˜"""
        # åˆ¤æ–­æ˜¯å¦æ¯”ç°æœ‰çš„æœ€ä½³æ¨¡å‹å¥½
        is_better = self._is_better(current_score)
        
        if len(self.best_models) < self.save_best_k:
            # å¦‚æœè¿˜æ²¡æœ‰è¾¾åˆ°ä¿å­˜æ•°é‡é™åˆ¶ï¼Œç›´æ¥æ·»åŠ 
            best_filename = f"best_{len(self.best_models)+1:02d}_epoch_{epoch:03d}_score_{current_score:.4f}"
            if self.save_format == 'h5':
                best_filepath = os.path.join(self.save_dir, 'best_models', f"{best_filename}.h5")
                if self.save_weights_only:
                    self.model.save_weights(best_filepath)
                else:
                    self.model.save(best_filepath)
            else:
                best_filepath = os.path.join(self.save_dir, 'best_models', best_filename)
                self.model.save(best_filepath, save_format='tf')
            
            self.best_models.append((current_score, epoch, best_filepath))
            # print(f"ğŸŒŸ Added to best models ({len(self.best_models)}/{self.save_best_k}): score={current_score:.4f}")
            
        elif is_better:
            # æ‰¾åˆ°æœ€å·®çš„æ¨¡å‹å¹¶æ›¿æ¢
            worst_idx = self._get_worst_model_idx()
            worst_score, worst_epoch, worst_path = self.best_models[worst_idx]
            
            # åˆ é™¤æœ€å·®çš„æ¨¡å‹æ–‡ä»¶
            try:
                if os.path.isdir(worst_path):
                    import shutil
                    shutil.rmtree(worst_path)
                else:
                    os.remove(worst_path)
                print(f"ğŸ—‘ï¸  Removed worse model: epoch_{worst_epoch}, score={worst_score:.4f}")
            except OSError as e:
                print(f"Warning: Could not remove {worst_path}: {e}")
            
            # ä¿å­˜æ–°çš„æœ€ä½³æ¨¡å‹
            best_filename = f"best_{worst_idx+1:02d}_epoch_{epoch:03d}_score_{current_score:.4f}"
            if self.save_format == 'h5':
                best_filepath = os.path.join(self.save_dir, 'best_models', f"{best_filename}.h5")
                if self.save_weights_only:
                    self.model.save_weights(best_filepath)
                else:
                    self.model.save(best_filepath)
            else:
                best_filepath = os.path.join(self.save_dir, 'best_models', best_filename)
                self.model.save(best_filepath, save_format='tf')
            
            self.best_models[worst_idx] = (current_score, epoch, best_filepath)
            print(f"ğŸŒŸ Updated best models: score={current_score:.4f} (replaced score={worst_score:.4f})")
    
    def _is_better(self, current_score):
        """åˆ¤æ–­å½“å‰åˆ†æ•°æ˜¯å¦æ›´å¥½"""
        if not self.best_models:
            return True
        
        worst_score = self._get_worst_score()
        if self.mode == 'min':
            return current_score < worst_score
        else:
            return current_score > worst_score
    
    def _get_worst_model_idx(self):
        """è·å–æœ€å·®æ¨¡å‹çš„ç´¢å¼•"""
        if self.mode == 'min':
            return max(range(len(self.best_models)), key=lambda i: self.best_models[i][0])
        else:
            return min(range(len(self.best_models)), key=lambda i: self.best_models[i][0])
    
    def _get_worst_score(self):
        """è·å–æœ€å·®åˆ†æ•°"""
        worst_idx = self._get_worst_model_idx()
        return self.best_models[worst_idx][0]
    
    def _save_training_history(self):
        """ä¿å­˜è®­ç»ƒå†å²"""
        # ä¿å­˜ä¸ºJSONæ ¼å¼ï¼ˆä¾¿äºé˜…è¯»ï¼‰
        json_path = os.path.join(self.save_dir, 'training_history.json')
        with open(json_path, 'w') as f:
            json.dump(self.epoch_history, f, indent=2)
        
        # ä¿å­˜ä¸ºYAMLæ ¼å¼
        yaml_path = os.path.join(self.save_dir, 'training_history.yaml')
        with open(yaml_path, 'w') as f:
            yaml.dump(self.epoch_history, f, default_flow_style=False)
        
        # ä¿å­˜ä¸ºpickleæ ¼å¼ï¼ˆä¾¿äºç¨‹åºè¯»å–ï¼‰
        pkl_path = os.path.join(self.save_dir, 'training_history.pkl')
        with open(pkl_path, 'wb') as f:
            pickle.dump(self.epoch_history, f)
    
    def _print_epoch_summary(self, epoch, logs):
        """æ‰“å°epochæ‘˜è¦"""
        # print(f"\nğŸ“Š Epoch {epoch} Summary:")
        # print(f"   Loss: {logs.get('loss', 0):.4f} | Val Loss: {logs.get('val_loss', 0):.4f}")
        # print(f"   Acc:  {logs.get('accuracy', 0):.4f} | Val Acc:  {logs.get('val_accuracy', 0):.4f}")
        
        if self.best_models:
            best_scores = [score for score, _, _ in self.best_models]
            best_score = min(best_scores) if self.mode == 'min' else max(best_scores)
            # print(f"   Best {self.monitor}: {best_score:.4f}")
    
    def on_train_end(self, logs=None):
        """è®­ç»ƒç»“æŸæ—¶è°ƒç”¨"""
        print(f"\nğŸ¯ Training completed!")
        print(f"ğŸ“ Models saved in: {self.save_dir}")
        print(f"ğŸ† Best {self.save_best_k} models saved in: {os.path.join(self.save_dir, 'best_models')}")
        
        # æ‰“å°æœ€ä½³æ¨¡å‹æ‘˜è¦
        if self.best_models:
            print(f"\nğŸŒŸ Best Models Summary:")
            sorted_models = sorted(self.best_models, key=lambda x: x[0], reverse=(self.mode == 'max'))
            for i, (score, epoch, filepath) in enumerate(sorted_models, 1):
                filename = os.path.basename(filepath)
                print(f"   {i}. Epoch {epoch}: {self.monitor}={score:.4f} -> {filename}")


class DetailedLoggingCallback(tf.keras.callbacks.Callback):
    """è¯¦ç»†çš„æ—¥å¿—è®°å½•å›è°ƒ"""
    
    def __init__(self, log_dir, log_frequency=1):
        """
        Args:
            log_dir: æ—¥å¿—ä¿å­˜ç›®å½•
            log_frequency: è®°å½•é¢‘ç‡ï¼ˆæ¯nä¸ªepochè®°å½•ä¸€æ¬¡ï¼‰
        """
        super().__init__()
        self.log_dir = log_dir
        self.log_frequency = log_frequency
        os.makedirs(log_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        self.log_file = os.path.join(log_dir, 'detailed_training.log')
        with open(self.log_file, 'w') as f:
            f.write(f"Training started at {datetime.now()}\n")
            f.write("=" * 80 + "\n")
    
    def on_epoch_end(self, epoch, logs=None):
        """è®°å½•è¯¦ç»†çš„epochä¿¡æ¯"""
        if (epoch + 1) % self.log_frequency == 0:
            logs = logs or {}
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            with open(self.log_file, 'a') as f:
                f.write(f"\nEpoch {epoch + 1} - {timestamp}\n")
                f.write("-" * 40 + "\n")
                for key, value in logs.items():
                    f.write(f"{key:15s}: {value:.6f}\n")
                f.write("-" * 40 + "\n")
    
    def on_train_end(self, logs=None):
        """è®­ç»ƒç»“æŸæ—¶è®°å½•"""
        with open(self.log_file, 'a') as f:
            f.write(f"\nTraining completed at {datetime.now()}\n")
            f.write("=" * 80 + "\n")


class MetricsVisualizationCallback(tf.keras.callbacks.Callback):
    """è®­ç»ƒæŒ‡æ ‡å¯è§†åŒ–å›è°ƒï¼ˆå¯é€‰ï¼Œéœ€è¦matplotlibï¼‰"""
    
    def __init__(self, save_dir, plot_frequency=5):
        """
        Args:
            save_dir: å›¾ç‰‡ä¿å­˜ç›®å½•
            plot_frequency: ç»˜å›¾é¢‘ç‡ï¼ˆæ¯nä¸ªepochç»˜åˆ¶ä¸€æ¬¡ï¼‰
        """
        super().__init__()
        self.save_dir = save_dir
        self.plot_frequency = plot_frequency
        self.metrics_history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}
        
        os.makedirs(save_dir, exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰matplotlib
        try:
            import matplotlib.pyplot as plt
            self.plt = plt
            self.plot_available = True
        except ImportError:
            print("Warning: matplotlib not available, skipping plots")
            self.plot_available = False
    
    def on_epoch_end(self, epoch, logs=None):
        """è®°å½•æŒ‡æ ‡å¹¶ç»˜å›¾"""
        if not self.plot_available:
            return
            
        logs = logs or {}
        
        # è®°å½•æŒ‡æ ‡
        for key in self.metrics_history:
            if key in logs:
                self.metrics_history[key].append(logs[key])
        
        # å®šæœŸç»˜å›¾
        if (epoch + 1) % self.plot_frequency == 0:
            self._plot_metrics(epoch + 1)
    
    def _plot_metrics(self, epoch):
        """ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡"""
        fig, (ax1, ax2) = self.plt.subplots(1, 2, figsize=(12, 4))
        
        # ç»˜åˆ¶æŸå¤±
        ax1.plot(self.metrics_history['loss'], label='Training Loss', color='blue')
        if self.metrics_history['val_loss']:
            ax1.plot(self.metrics_history['val_loss'], label='Validation Loss', color='red')
        ax1.set_title('Model Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # ç»˜åˆ¶å‡†ç¡®ç‡
        ax2.plot(self.metrics_history['accuracy'], label='Training Accuracy', color='blue')
        if self.metrics_history['val_accuracy']:
            ax2.plot(self.metrics_history['val_accuracy'], label='Validation Accuracy', color='red')
        ax2.set_title('Model Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True)
        
        # ä¿å­˜å›¾ç‰‡
        plot_path = os.path.join(self.save_dir, f'training_metrics_epoch_{epoch:03d}.png')
        self.plt.tight_layout()
        self.plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        self.plt.close()
        
        # print(f"ğŸ“ˆ Metrics plot saved: {os.path.basename(plot_path)}")
