"""
ä¸“ç”¨æµ‹è¯•è„šæœ¬ - åªæµ‹è¯•ï¼Œä¸è®­ç»ƒ
ç”¨äºæµ‹è¯•æ–‡ä»¶å¤¹ä¸­çš„æ¨¡å‹æ–‡ä»¶
"""
import os
import yaml
import getopt
import sys
import glob
import pandas as pd
from datetime import datetime

import numpy as np
from tensorflow.keras import backend as K

from action_predict import action_prediction
from jaad_data import JAAD
from pie_data import PIE
from watch_ped_data import WATCH_PED

import tensorflow as tf

# è®¾ç½®GPU
gpus = tf.config.experimental.list_physical_devices('GPU')
if len(gpus) > 0:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)

# æ•°æ®é›†è·¯å¾„
path_jaad = "/home/minshi/Pedestrian_Crossing_Intention_Prediction/JAAD"
path_pie = "/media/minshi/WD_2T/PIE/annotations"
path_watch_ped = "/home/minshi/Pedestrian_Crossing_Intention_Prediction/Watch_Ped"


def load_config_from_path(path):
    """ä»è·¯å¾„åŠ è½½é…ç½®æ–‡ä»¶
    å‚æ•°:
    - path: å¯ä»¥æ˜¯æ¨¡å‹ç›®å½•æˆ–å•ä¸ªæ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    if os.path.isfile(path):
        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œæ‰¾åˆ°çˆ¶ç›®å½•
        model_dir = os.path.dirname(path)
        # å¦‚æœåœ¨epochså­ç›®å½•ä¸­ï¼Œéœ€è¦å‘ä¸Šä¸€çº§æ‰¾é…ç½®æ–‡ä»¶
        if os.path.basename(model_dir) == 'epochs':
            model_dir = os.path.dirname(model_dir)
    else:
        # å¦‚æœæ˜¯ç›®å½•
        model_dir = path
    
    config_path = os.path.join(model_dir, 'configs.yaml')
    if os.path.exists(config_path):
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    else:
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")


def get_model_files(path):
    """è·å–æ¨¡å‹æ–‡ä»¶åˆ—è¡¨
    å‚æ•°:
    - path: å¯ä»¥æ˜¯æ¨¡å‹ç›®å½•æˆ–å•ä¸ªæ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    model_files = []
    
    # å¦‚æœæ˜¯å•ä¸ªæ–‡ä»¶
    if os.path.isfile(path) and path.endswith('.h5'):
        return [path]
    
    # å¦‚æœæ˜¯ç›®å½•
    if os.path.isdir(path):
        # æŸ¥æ‰¾ .h5 æ–‡ä»¶
        h5_files = glob.glob(os.path.join(path, "*.h5"))
        for f in h5_files:
            model_files.append(f)
        
        # æŸ¥æ‰¾ epochs å­ç›®å½•ä¸­çš„æ–‡ä»¶
        epochs_dir = os.path.join(path, "epochs")
        if os.path.exists(epochs_dir):
            epoch_files = glob.glob(os.path.join(epochs_dir, "*.h5"))
            model_files.extend(epoch_files)
    
    return sorted(model_files)


def test_single_model(model_file_path, configs, imdb, beh_seq_test):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹æ–‡ä»¶"""
    print(f"\nğŸ” æµ‹è¯•æ¨¡å‹: {os.path.basename(model_file_path)}")
    
    try:
        from tensorflow.keras.models import load_model
        from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score
        
        # è·å–æ¨¡å‹ç±»
        method_class = action_prediction(configs['model_opts']['model'])(
            dataset=configs['model_opts']['dataset'], 
            sample_type=configs['data_opts']['sample_type'], 
            **configs['net_opts']
        )
        
        # ç›´æ¥åŠ è½½æ¨¡å‹æ–‡ä»¶
        test_model = load_model(model_file_path)
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_data = method_class.get_data('test', beh_seq_test, {**configs['model_opts'], 'batch_size': 1})
        
        # è¿›è¡Œé¢„æµ‹
        test_results = test_model.predict(test_data['data'][0], batch_size=1, verbose=1)
        
        # è®¡ç®—æŒ‡æ ‡
        acc = accuracy_score(test_data['data'][1], np.round(test_results))
        f1 = f1_score(test_data['data'][1], np.round(test_results))
        auc = roc_auc_score(test_data['data'][1], np.round(test_results))
        precision = precision_score(test_data['data'][1], np.round(test_results))
        recall = recall_score(test_data['data'][1], np.round(test_results))
        
        return {
            'model_file': os.path.basename(model_file_path),
            'model_path': model_file_path,
            'accuracy': float(acc),
            'auc': float(auc),
            'f1': float(f1),
            'precision': float(precision),
            'recall': float(recall),
            'status': 'success'
        }
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return {
            'model_file': os.path.basename(model_file_path),
            'model_path': model_file_path,
            'accuracy': 0.0,
            'auc': 0.0,
            'f1': 0.0,
            'precision': 0.0,
            'recall': 0.0,
            'status': f'error: {str(e)}'
        }


def test_model_path(path):
    """æµ‹è¯•æ¨¡å‹è·¯å¾„ä¸­çš„æ¨¡å‹
    å‚æ•°:
    - path: å¯ä»¥æ˜¯æ¨¡å‹ç›®å½•æˆ–å•ä¸ªæ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    if os.path.isfile(path):
        print(f"ğŸš€ å¼€å§‹æµ‹è¯•å•ä¸ªæ¨¡å‹: {os.path.basename(path)}")
    else:
        print(f"ğŸš€ å¼€å§‹æµ‹è¯•æ¨¡å‹ç›®å½•: {path}")
    
    # åŠ è½½é…ç½®
    configs = load_config_from_path(path)
    print("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
    
    # åˆå§‹åŒ–æ•°æ®é›†
    if configs['model_opts']['dataset'] == 'pie':
        imdb = PIE(data_path=path_pie)
    elif configs['model_opts']['dataset'] == 'jaad':
        imdb = JAAD(data_path=path_jaad)
    elif configs['model_opts']['dataset'] in ["watch_ped", "watch"]:
        imdb = WATCH_PED(data_path=path_watch_ped)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {configs['model_opts']['dataset']}")
    
    print("âœ… æ•°æ®é›†åˆå§‹åŒ–æˆåŠŸ")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ç›¸åŒçš„é¢„å¤„ç†æ­¥éª¤ï¼‰
    print("ğŸ”„ ç”Ÿæˆæµ‹è¯•æ•°æ®...")
    beh_seq_test = imdb.generate_data_trajectory_sequence('test', **configs['data_opts'])
    print("âœ… æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ")
    
    # è·å–æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
    model_files = get_model_files(path)
    print(f"ğŸ“ æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")
    
    if not model_files:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        return
    
    # æµ‹è¯•ç»“æœåˆ—è¡¨
    results = []
    
    # é€ä¸ªæµ‹è¯•æ¨¡å‹
    for i, model_path in enumerate(model_files, 1):
        print(f"\n{'='*60}")
        if len(model_files) == 1:
            print(f"æµ‹è¯•å•ä¸ªæ¨¡å‹")
        else:
            print(f"è¿›åº¦: {i}/{len(model_files)}")
        
        result = test_single_model(model_path, configs, imdb, beh_seq_test)
        results.append(result)
        
        if result['status'] == 'success':
            print(f"âœ… å‡†ç¡®ç‡: {result['accuracy']:.4f}, AUC: {result['auc']:.4f}, F1: {result['f1']:.4f}")
        else:
            print(f"âŒ {result['status']}")
    
    # ç¡®å®šä¿å­˜ç›®å½•
    if os.path.isfile(path):
        save_dir = os.path.dirname(path)
        if os.path.basename(save_dir) == 'epochs':
            save_dir = os.path.dirname(save_dir)
    else:
        save_dir = path
    
    # ä¿å­˜ç»“æœ
    save_results(save_dir, results, configs)
    
    # æ˜¾ç¤ºæ±‡æ€»
    display_summary(results)


def save_results(model_dir, results, configs):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜ä¸ºCSV
    df = pd.DataFrame(results)
    csv_path = os.path.join(model_dir, f'test_results_{timestamp}.csv')
    df.to_csv(csv_path, index=False)
    print(f"\nğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_path = os.path.join(model_dir, f'test_report_{timestamp}.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("æ¨¡å‹æµ‹è¯•æŠ¥å‘Š (Model Test Report)\n")
        f.write("="*80 + "\n")
        f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ¨¡å‹ç›®å½•: {model_dir}\n")
        f.write(f"æ•°æ®é›†: {configs['model_opts']['dataset']}\n")
        f.write(f"æ¨¡å‹ç±»å‹: {configs['model_opts']['model']}\n")
        f.write(f"æ ·æœ¬ç±»å‹: {configs['data_opts']['sample_type']}\n\n")
        
        f.write("æµ‹è¯•ç»“æœæ±‡æ€»:\n")
        f.write("-"*80 + "\n")
        
        success_results = [r for r in results if r['status'] == 'success']
        if success_results:
            df_success = pd.DataFrame(success_results)
            f.write(f"æˆåŠŸæµ‹è¯•æ¨¡å‹æ•°é‡: {len(success_results)}\n")
            f.write(f"å¹³å‡å‡†ç¡®ç‡: {df_success['accuracy'].mean():.4f}\n")
            f.write(f"æœ€é«˜å‡†ç¡®ç‡: {df_success['accuracy'].max():.4f}\n")
            f.write(f"å¹³å‡AUC: {df_success['auc'].mean():.4f}\n")
            f.write(f"æœ€é«˜AUC: {df_success['auc'].max():.4f}\n")
            f.write(f"å¹³å‡F1: {df_success['f1'].mean():.4f}\n")
            f.write(f"æœ€é«˜F1: {df_success['f1'].max():.4f}\n\n")
            
            # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
            best_acc_idx = df_success['accuracy'].idxmax()
            best_auc_idx = df_success['auc'].idxmax()
            best_f1_idx = df_success['f1'].idxmax()
            
            f.write("æœ€ä½³æ¨¡å‹:\n")
            f.write(f"æœ€é«˜å‡†ç¡®ç‡æ¨¡å‹: {success_results[best_acc_idx]['model_file']} (Acc: {success_results[best_acc_idx]['accuracy']:.4f})\n")
            f.write(f"æœ€é«˜AUCæ¨¡å‹: {success_results[best_auc_idx]['model_file']} (AUC: {success_results[best_auc_idx]['auc']:.4f})\n")
            f.write(f"æœ€é«˜F1æ¨¡å‹: {success_results[best_f1_idx]['model_file']} (F1: {success_results[best_f1_idx]['f1']:.4f})\n\n")
        
        f.write("è¯¦ç»†ç»“æœ:\n")
        f.write("-"*80 + "\n")
        for result in results:
            f.write(f"æ¨¡å‹: {result['model_file']}\n")
            if result['status'] == 'success':
                f.write(f"  å‡†ç¡®ç‡: {result['accuracy']:.4f}\n")
                f.write(f"  AUC: {result['auc']:.4f}\n")
                f.write(f"  F1: {result['f1']:.4f}\n")
                f.write(f"  ç²¾ç¡®ç‡: {result['precision']:.4f}\n")
                f.write(f"  å¬å›ç‡: {result['recall']:.4f}\n")
            else:
                f.write(f"  çŠ¶æ€: {result['status']}\n")
            f.write("\n")
    
    print(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def display_summary(results):
    """æ˜¾ç¤ºæµ‹è¯•ç»“æœæ±‡æ€»"""
    success_results = [r for r in results if r['status'] == 'success']
    failed_results = [r for r in results if r['status'] != 'success']
    
    print("\n" + "="*80)
    print("ğŸ¯ æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*80)
    print(f"æ€»æ¨¡å‹æ•°é‡: {len(results)}")
    print(f"æˆåŠŸæµ‹è¯•: {len(success_results)}")
    print(f"å¤±è´¥æµ‹è¯•: {len(failed_results)}")
    
    if success_results:
        df = pd.DataFrame(success_results)
        print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"å¹³å‡å‡†ç¡®ç‡: {df['accuracy'].mean():.4f} (Â±{df['accuracy'].std():.4f})")
        print(f"å¹³å‡AUC: {df['auc'].mean():.4f} (Â±{df['auc'].std():.4f})")
        print(f"å¹³å‡F1: {df['f1'].mean():.4f} (Â±{df['f1'].std():.4f})")
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹:")
        best_acc = df.loc[df['accuracy'].idxmax()]
        best_auc = df.loc[df['auc'].idxmax()]
        best_f1 = df.loc[df['f1'].idxmax()]
        
        print(f"æœ€é«˜å‡†ç¡®ç‡: {best_acc['model_file']} (Acc: {best_acc['accuracy']:.4f})")
        print(f"æœ€é«˜AUC: {best_auc['model_file']} (AUC: {best_auc['auc']:.4f})")
        print(f"æœ€é«˜F1: {best_f1['model_file']} (F1: {best_f1['f1']:.4f})")


def usage():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print('ä¸“ç”¨æ¨¡å‹æµ‹è¯•è„šæœ¬ - æ”¯æŒæµ‹è¯•å•ä¸ªæ¨¡å‹æˆ–æ•´ä¸ªç›®å½•')
    print('ç”¨æ³•: python compare_all_epochs.py [é€‰é¡¹]')
    print('é€‰é¡¹:')
    print('-h, --help\t\t', 'æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯')
    print('-d, --model_dir\t', 'æ¨¡å‹ç›®å½•è·¯å¾„')
    print('-f, --model_file\t', 'å•ä¸ªæ¨¡å‹æ–‡ä»¶è·¯å¾„')
    print()
    print('ç¤ºä¾‹:')
    print('# æµ‹è¯•æ•´ä¸ªç›®å½•')
    print('python compare_all_epochs.py -d /path/to/model/directory')
    print('# æµ‹è¯•å•ä¸ªæ¨¡å‹')
    print('python compare_all_epochs.py -f /path/to/model.h5')
    print()


if __name__ == '__main__':
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'hd:f:', ['help', 'model_dir=', 'model_file='])
    except getopt.GetoptError as err:
        print(str(err))
        usage()
        sys.exit(2)

    model_path = None

    for o, a in opts:
        if o in ["-h", "--help"]:
            usage()
            sys.exit(0)
        elif o in ['-d', '--model_dir']:
            model_path = a
        elif o in ['-f', '--model_file']:
            model_path = a

    if not model_path:
        print('\x1b[1;37;41m' + 'ERROR: è¯·æä¾›æ¨¡å‹ç›®å½•è·¯å¾„(-d)æˆ–æ¨¡å‹æ–‡ä»¶è·¯å¾„(-f)!' + '\x1b[0m')
        usage()
        sys.exit(2)

    if not os.path.exists(model_path):
        print(f'\x1b[1;37;41m' + f'ERROR: è·¯å¾„ä¸å­˜åœ¨: {model_path}' + '\x1b[0m')
        sys.exit(2)

    test_model_path(model_path)
